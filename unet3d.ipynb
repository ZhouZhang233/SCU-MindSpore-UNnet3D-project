{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "一、数据集准备\n",
    "    1、下载LUNA16数据集到本地，放在data文件夹中\n",
    "    2、进入路径./data/LUNA16, 将得到的subset0-9.rar和seg-lungs-LUNA16.rar共11个文件解压\n",
    "    3、设置路径，运行下面代码，划分训练集和验证集，并且将数据格式转化为niffi，得到如下的文件结构\n",
    "    ./train\n",
    "        /image\n",
    "        /seg\n",
    "    ./val\n",
    "        /image\n",
    "        /seg\n",
    "    注：\n",
    "        （1）LUNA16数据集共887个volume，我们选择subset9的最后三个volume作为验证集，subset0-8进而subset9剩下的部分作为训练集。\n",
    "        （2）可以通过下载ITK-SNAP软件可视化图片和分割标签"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function: Adjust Data Content Structure & Convert volume to nifti format\n",
    "# Author: Zhang Zhongzhou\n",
    "# Date: 2022/9/16\n",
    "# LUNA16\n",
    "#   /train\n",
    "#       /image\n",
    "#       /seg\n",
    "#   /val\n",
    "#       /image\n",
    "#       /seg\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import SimpleITK as sitk\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from src.model_utils.config import config\n",
    "\n",
    "def convert_nifti(input_im, save_image, roi_size):\n",
    "    \"\"\"\n",
    "    Convert dataset into mifti format.\n",
    "\n",
    "    Args:\n",
    "        input_im(str): input image name\n",
    "        save_image(str): output image name\n",
    "        roi_size(list): The size to crop the image\n",
    "    \"\"\"\n",
    "    img = sitk.ReadImage(input_im)\n",
    "    image_array = sitk.GetArrayFromImage(img)\n",
    "    D, H, W = image_array.shape\n",
    "    if H < roi_size[0] or W < roi_size[1] or D < roi_size[2]:\n",
    "        print(\"file {} size is smaller than roi size, ignore it.\".format(input_im))\n",
    "        # continue\n",
    "    sitk.WriteImage(img, save_image)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    root = \"../data/LUNA16\"\n",
    "    image_fold = [\"subset0\",\"subset1\",\"subset2\",\"subset3\",\"subset4\",\"subset5\",\"subset6\",\"subset7\",\"subset8\",\"subset9\"]\n",
    "    label_fold = \"seg-lungs-LUNA16\"\n",
    "\n",
    "    save_train_image_path = osp.join(root, \"train\", \"image\")\n",
    "    save_train_seg_path = osp.join(root, \"train\", \"seg\")\n",
    "    save_val_image_path = osp.join(root, \"val\", \"image\")\n",
    "    save_val_seg_path = osp.join(root, \"val\", \"seg\")\n",
    "\n",
    "    # create save path\n",
    "    if not os.path.exists(save_train_image_path):\n",
    "        os.makedirs(save_train_image_path)\n",
    "    if not os.path.exists(save_train_seg_path):\n",
    "        os.makedirs(save_train_seg_path)\n",
    "    if not os.path.exists(save_val_image_path):\n",
    "        os.makedirs(save_val_image_path)\n",
    "    if not os.path.exists(save_val_seg_path):\n",
    "        os.makedirs(save_val_seg_path)\n",
    "\n",
    "    # split train and val\n",
    "    # Here we select the last 10 volume in subset9 for validation\n",
    "    for subset in image_fold:\n",
    "        image_list = sorted(glob.glob(osp.join(root, subset, \"*.mhd\")))\n",
    "        for im in tqdm(image_list):\n",
    "                im_name = im.split(\"/\")[-1][:-4]\n",
    "                seg = osp.join(root, label_fold, im_name + \".mhd\")\n",
    "                save_im_name = osp.join(save_train_image_path, im_name+\".nii.gz\")\n",
    "                save_seg_name = osp.join(save_train_seg_path, im_name + \".nii.gz\")\n",
    "                convert_nifti(im, save_im_name, config.roi_size)\n",
    "                convert_nifti(seg, save_seg_name, config.roi_size)\n",
    "\n",
    "    all_images = sorted(os.listdir(save_train_image_path))[-10:]\n",
    "    all_segs = sorted(os.listdir(save_train_seg_path))[-10:]\n",
    "    for i, name in enumerate(all_images):\n",
    "        sou_im = osp.join(save_train_image_path, name)\n",
    "        sou_seg = osp.join(save_train_seg_path, name)\n",
    "        shutil.move(sou_im, save_val_image_path)\n",
    "        shutil.move(sou_seg, save_val_seg_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualize on ITK-SNAP\n",
    "import cv2\n",
    "im = cv2.imread(\"image/visual_data.jpg\", 1)\n",
    "cv2.imshow(\"vis_data\", im)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "二、参数设置（训练参数和测试参数）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def get_config():\n",
    "    \"\"\"\n",
    "    Get Config according to the yaml file and cli arguments.\n",
    "    \"\"\"\n",
    "    cfg = ml_collections.ConfigDict()\n",
    "    # Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)\n",
    "    # args = argparse.ArgumentParser(description=\"default name\", add_help=False)\n",
    "    cfg.enable_fp16_gpu=False\n",
    "    cfg.enable_modelarts=False\n",
    "    # Url for modelarts\n",
    "    cfg.data_url=\"\"\n",
    "    cfg.train_ur=\"\"\n",
    "    cfg.checkpoint_url=\"\"\n",
    "    # Path for local\n",
    "    cfg.run_distribute=False\n",
    "    cfg.enable_profiling=False\n",
    "    cfg.data_path=\"data/LUNA16/train/\"\n",
    "    cfg.output_path=\"output\"\n",
    "    cfg.load_path=\"/checkpoint_path/\"\n",
    "    cfg.device_target=\"GPU\"\n",
    "    cfg.checkpoint_path=\"./checkpoint/\"\n",
    "    cfg.checkpoint_file_path=\"Unet3d-10-110.ckpt\"\n",
    "\n",
    "    # ==============================================================================\n",
    "    # data loader options\n",
    "    cfg.num_worker = 4\n",
    "    # Training options\n",
    "    cfg.max_epoch = 10\n",
    "    cfg.lr=0.0005\n",
    "    cfg.batch_size=1\n",
    "    cfg.epoch_size=10\n",
    "    cfg.warmup_step=120\n",
    "    cfg.warmup_ratio=0.3\n",
    "    cfg.num_classes=4\n",
    "    cfg.in_channels=1\n",
    "    cfg.keep_checkpoint_max=1\n",
    "    cfg.loss_scale=256.0\n",
    "    cfg.roi_size=[224, 224, 96]\n",
    "    cfg.overlap=0.25\n",
    "    cfg.min_val=-500\n",
    "    cfg.max_val=1000\n",
    "    cfg.upper_limit=5\n",
    "    cfg.lower_limit=3\n",
    "\n",
    "    # Export options\n",
    "    cfg.device_id=0\n",
    "    cfg.ckpt_file=\"./checkpoint/Unet3d-10-110.ckpt\"\n",
    "    cfg.file_name=\"unet3d\"\n",
    "    cfg.file_format=\"MINDIR\"\n",
    "\n",
    "    # 310 infer options\n",
    "    cfg.pre_result_path=\"./preprocess_Result\"\n",
    "    cfg.post_result_path=\"./result_Files\"\n",
    "\n",
    "    return cfg\n",
    "\n",
    "config = get_config()\n",
    "# print(config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "三、定义数据预处理的transform"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# transforms\n",
    "import re\n",
    "import numpy as np\n",
    "import logger\n",
    "\n",
    "np_str_obj_array_pattern = re.compile(r'[SaUO]')\n",
    "\n",
    "def correct_nifti_head(img):\n",
    "    \"\"\"\n",
    "    Check nifti object header's format, update the header if needed.\n",
    "    In the updated image pixdim matches the affine.\n",
    "\n",
    "    Args:\n",
    "        img: nifti image object\n",
    "    \"\"\"\n",
    "    dim = img.header[\"dim\"][0]\n",
    "    if dim >= 5:\n",
    "        return img\n",
    "    pixdim = np.asarray(img.header.get_zooms())[:dim]\n",
    "    norm_affine = np.sqrt(np.sum(np.square(img.affine[:dim, :dim]), 0))\n",
    "    if np.allclose(pixdim, norm_affine):\n",
    "        return img\n",
    "    # if hasattr(img, \"get_sform\"):\n",
    "    #     return rectify_header_sform_qform(img)\n",
    "    return img\n",
    "\n",
    "class LoadData:\n",
    "    \"\"\"\n",
    "    Load Image data from provided files.\n",
    "    \"\"\"\n",
    "    def __init__(self, canonical=False, dtype=np.float32):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        canonical: if True, load the image as closest to canonical axis format.\n",
    "        dtype: convert the loaded image to this data type.\n",
    "        \"\"\"\n",
    "        self.canonical = canonical\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def operation(self, filename):\n",
    "        img_array = list()\n",
    "        compatible_meta = dict()\n",
    "        filename = filename.item()\n",
    "        filename = [filename]\n",
    "        for name in filename:\n",
    "            img = nib.load(str(name)[2:-1])\n",
    "            img = correct_nifti_head(img)\n",
    "            header = dict(img.header)\n",
    "            header[\"filename_or_obj\"] = name\n",
    "            header[\"affine\"] = img.affine\n",
    "            header[\"original_affine\"] = img.affine.copy()\n",
    "            header[\"canonical\"] = self.canonical\n",
    "            ndim = img.header[\"dim\"][0]\n",
    "            spatial_rank = min(ndim, 3)\n",
    "            header[\"spatial_shape\"] = img.header[\"dim\"][1 : spatial_rank + 1]\n",
    "            if self.canonical:\n",
    "                img = nib.as_closest_canonical(img)\n",
    "                header[\"affine\"] = img.affine\n",
    "            img_array.append(np.array(img.get_fdata(dtype=self.dtype)))\n",
    "            img.uncache()\n",
    "            if not compatible_meta:\n",
    "                for meta_key in header:\n",
    "                    meta_datum = header[meta_key]\n",
    "                    if isinstance(meta_datum, np.ndarray) \\\n",
    "                        and np_str_obj_array_pattern.search(meta_datum.dtype.str) is not None:\n",
    "                        continue\n",
    "                    compatible_meta[meta_key] = meta_datum\n",
    "            else:\n",
    "                assert np.allclose(header[\"affine\"], compatible_meta[\"affine\"])\n",
    "\n",
    "        img_array = np.stack(img_array, axis=0) if len(img_array) > 1 else img_array[0]\n",
    "        return img_array\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        img_array = self.operation(img)\n",
    "        seg_array = self.operation(label)\n",
    "        return img_array, seg_array\n",
    "\n",
    "class ExpandChannel:\n",
    "    \"\"\"\n",
    "    Expand a 1-length channel dimension to the input image.\n",
    "    \"\"\"\n",
    "    def __call__(self, img, label):\n",
    "        img_array = img[None]\n",
    "        seg_array = label[None]\n",
    "        return img_array, seg_array\n",
    "\n",
    "class Orientation:\n",
    "    \"\"\"\n",
    "    Change the input image's orientation into the specified based on `ax`.\n",
    "    \"\"\"\n",
    "    def __init__(self, ax=\"RAS\", labels=tuple(zip(\"LPI\", \"RAS\"))):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ax: N elements sequence for ND input's orientation.\n",
    "            labels: optional, None or sequence of (2,) sequences\n",
    "                (2,) sequences are labels for (beginning, end) of output axis.\n",
    "        \"\"\"\n",
    "        self.ax = ax\n",
    "        self.labels = labels\n",
    "\n",
    "    def operation(self, data, affine=None):\n",
    "        \"\"\"\n",
    "        original orientation of `data` is defined by `affine`.\n",
    "\n",
    "        Args:\n",
    "            data: in shape (num_channels, H[, W, ...]).\n",
    "            affine (matrix): (N+1)x(N+1) original affine matrix for spatially ND `data`. Defaults to identity.\n",
    "\n",
    "        Returns:\n",
    "            data (reoriented in `self.ax`), original ax, current ax.\n",
    "        \"\"\"\n",
    "        if data.ndim <= 1:\n",
    "            raise ValueError(\"data must have at least one spatial dimension.\")\n",
    "        if affine is None:\n",
    "            affine = np.eye(data.ndim, dtype=np.float64)\n",
    "            affine_copy = affine\n",
    "        else:\n",
    "            affine_copy = to_affine_nd(data.ndim-1, affine)\n",
    "        src = nib.io_orientation(affine_copy)\n",
    "        dst = nib.orientations.axcodes2ornt(self.ax[:data.ndim-1], labels=self.labels)\n",
    "        spatial_ornt = nib.orientations.ornt_transform(src, dst)\n",
    "        ornt = spatial_ornt.copy()\n",
    "        ornt[:, 0] += 1\n",
    "        ornt = np.concatenate([np.array([[0, 1]]), ornt])\n",
    "        data = nib.orientations.apply_orientation(data, ornt)\n",
    "        return data\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        img_array = self.operation(img)\n",
    "        seg_array = self.operation(label)\n",
    "        return img_array, seg_array\n",
    "\n",
    "class ScaleIntensityRange:\n",
    "    \"\"\"\n",
    "    Apply specific intensity scaling to the whole numpy array.\n",
    "    Scaling from [src_min, src_max] to [tgt_min, tgt_max] with clip option.\n",
    "\n",
    "    Args:\n",
    "        src_min: intensity original range min.\n",
    "        src_max: intensity original range max.\n",
    "        tgt_min: intensity target range min.\n",
    "        tgt_max: intensity target range max.\n",
    "        is_clip: whether to clip after scaling.\n",
    "    \"\"\"\n",
    "    def __init__(self, src_min, src_max, tgt_min, tgt_max, is_clip=False):\n",
    "        self.src_min = src_min\n",
    "        self.src_max = src_max\n",
    "        self.tgt_min = tgt_min\n",
    "        self.tgt_max = tgt_max\n",
    "        self.is_clip = is_clip\n",
    "\n",
    "    def operation(self, data):\n",
    "        if self.src_max - self.src_min == 0.0:\n",
    "            logger.warning(\"Divide by zero (src_min == src_max)\")\n",
    "            return data - self.src_min + self.tgt_min\n",
    "        data = (data - self.src_min) / (self.src_max - self.src_min)\n",
    "        data = data * (self.tgt_max - self.tgt_min) + self.tgt_min\n",
    "        if self.is_clip:\n",
    "            data = np.clip(data, self.tgt_min, self.tgt_max)\n",
    "        return data\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "        image = self.operation(image)\n",
    "        return image, label\n",
    "\n",
    "class RandomCropSamples:\n",
    "    def __init__(self, roi_size, num_samples=1):\n",
    "        self.roi_size = roi_size\n",
    "        self.num_samples = num_samples\n",
    "        self.set_random_state(0)\n",
    "\n",
    "    def set_random_state(self, seed=None):\n",
    "        \"\"\"\n",
    "        Set the random seed to control the slice size.\n",
    "\n",
    "        Args:\n",
    "            seed: set the random state with an integer seed.\n",
    "        \"\"\"\n",
    "        MAX_SEED = np.iinfo(np.uint32).max + 1\n",
    "        if seed is not None:\n",
    "            _seed = seed % MAX_SEED\n",
    "            self.rand_fn = np.random.RandomState(_seed)\n",
    "        else:\n",
    "            self.rand_fn = np.random.RandomState()\n",
    "        return self\n",
    "\n",
    "    def get_random_patch(self, dims, patch_size, rand_fn=None):\n",
    "        \"\"\"\n",
    "        Returns a tuple of slices to define a random patch in an array of shape `dims` with size `patch_size`.\n",
    "        \"\"\"\n",
    "        rand_int = np.random.randint if rand_fn is None else rand_fn.randint\n",
    "        min_corner = tuple(rand_int(0, ms - ps + 1) if ms > ps else 0 for ms, ps in zip(dims, patch_size))\n",
    "        return tuple(slice(mc, mc + ps) for mc, ps in zip(min_corner, patch_size))\n",
    "\n",
    "    def get_random_slice(self, img_size):\n",
    "        slices = (slice(None),) + self.get_random_patch(img_size, self.roi_size, self.rand_fn)\n",
    "        return slices\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "        res_image = []\n",
    "        res_label = []\n",
    "        for _ in range(self.num_samples):\n",
    "            slices = self.get_random_slice(image.shape[1:])\n",
    "            img = image[slices]\n",
    "            label_crop = label[slices]\n",
    "            res_image.append(img)\n",
    "            res_label.append(label_crop)\n",
    "        return np.array(res_image), np.array(res_label)\n",
    "\n",
    "class OneHot:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def one_hot(self, labels):\n",
    "        N, K = labels.shape\n",
    "        one_hot_encoding = np.zeros((N, self.num_classes, K), dtype=np.float32)\n",
    "        for i in range(N):\n",
    "            for j in range(K):\n",
    "                one_hot_encoding[i, labels[i][j], j] = 1\n",
    "        return one_hot_encoding\n",
    "\n",
    "    def operation(self, labels):\n",
    "        N, _, D, H, W = labels.shape\n",
    "        labels = labels.astype(np.int32)\n",
    "        labels = np.reshape(labels, (N, -1))\n",
    "        labels = self.one_hot(labels)\n",
    "        labels = np.reshape(labels, (N, self.num_classes, D, H, W))\n",
    "        return labels\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "        label = self.operation(label)\n",
    "        return image, label\n",
    "\n",
    "class ConvertLabel:\n",
    "    \"\"\"\n",
    "    Crop at the center of image with specified ROI size.\n",
    "    Args:\n",
    "        roi_size: the spatial size of the crop region e.g. [224,224,128]\n",
    "        If its components have non-positive values, the corresponding size of input image will be used.\n",
    "    \"\"\"\n",
    "    def operation(self, data):\n",
    "        \"\"\"\n",
    "        Apply the transform to `img`, assuming `img` is channel-first and\n",
    "        slicing doesn't apply to the channel dim.\n",
    "        \"\"\"\n",
    "        data[data > config.upper_limit] = 0\n",
    "        data = data - (config.lower_limit - 1)\n",
    "        data = np.clip(data, 0, config.lower_limit)\n",
    "        return data\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "        label = self.operation(label)\n",
    "        return image, label\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "四、创建dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataloader successfully!!\n",
      "train dataset length is: 877\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import mindspore.dataset as ds\n",
    "from mindspore.dataset.transforms.transforms import Compose\n",
    "import nibabel as nib\n",
    "import os\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, data, seg):\n",
    "        self.data = data\n",
    "        self.seg = seg\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        seg = self.seg[index]\n",
    "        return [data], [seg]\n",
    "\n",
    "def create_dataset(data_path, seg_path, rank_size=1, rank_id=0, is_training=True):\n",
    "    seg_files = sorted(glob.glob(os.path.join(seg_path, \"*.nii.gz\")))\n",
    "    train_files = [os.path.join(data_path, os.path.basename(seg)) for seg in seg_files]\n",
    "    train_ds = Dataset(data=train_files, seg=seg_files)\n",
    "    train_loader = ds.GeneratorDataset(train_ds, column_names=[\"image\", \"seg\"], num_parallel_workers=config.num_worker, \\\n",
    "                                       shuffle=is_training, num_shards=rank_size, shard_id=rank_id)\n",
    "\n",
    "    if is_training:\n",
    "        transform_image = Compose([LoadData(),\n",
    "                                   ExpandChannel(),\n",
    "                                   Orientation(),\n",
    "                                   ScaleIntensityRange(src_min=config.min_val, src_max=config.max_val, tgt_min=0.0, \\\n",
    "                                                       tgt_max=1.0, is_clip=True),\n",
    "                                   RandomCropSamples(roi_size=config.roi_size, num_samples=4),\n",
    "                                   ConvertLabel(),\n",
    "                                   OneHot(num_classes=config.num_classes)])\n",
    "    else:\n",
    "        transform_image = Compose([LoadData(),\n",
    "                                   ExpandChannel(),\n",
    "                                   Orientation(),\n",
    "                                   ScaleIntensityRange(src_min=config.min_val, src_max=config.max_val, tgt_min=0.0, \\\n",
    "                                                       tgt_max=1.0, is_clip=True),\n",
    "                                   ConvertLabel()])\n",
    "\n",
    "    train_loader = train_loader.map(operations=transform_image,\n",
    "                                    input_columns=[\"image\", \"seg\"],\n",
    "                                    num_parallel_workers=config.num_worker,\n",
    "                                    python_multiprocessing=True)\n",
    "    if not is_training:\n",
    "        train_loader = train_loader.batch(1)\n",
    "    return train_loader\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # cfg.data_path\n",
    "    train_dataset = create_dataset(data_path=config.data_path+\"image\",\\\n",
    "                                   seg_path=config.data_path+\"seg\", \\\n",
    "                                   is_training=True)\n",
    "    train_data_size = train_dataset.get_dataset_size()\n",
    "    print(\"create dataloader successfully!!\")\n",
    "    print(\"train dataset length is:\", train_data_size)\n",
    "    # for image, label in train_dataset.create_tuple_iterator():\n",
    "    #     print(\"image size: {}\".format(image.shape))\n",
    "    #     break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "五、构建UNet3d网络结构"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet3D model input: (1, 1, 224, 224, 96)\n",
      "UNet3D model output: (1, 4, 224, 224, 96)\n",
      "UNet3d<\n",
      "  (down1): Down<\n",
      "    (down_conv): ResidualUnit<\n",
      "      (down_conv_1): Conv3d<input_channels=1, output_channels=16, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal1): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=16, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=down1.down_conv.batchNormal1.bn2d.gamma, shape=(16,), dtype=Float32, requires_grad=True), beta=Parameter (name=down1.down_conv.batchNormal1.bn2d.beta, shape=(16,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=down1.down_conv.batchNormal1.bn2d.moving_mean, shape=(16,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=down1.down_conv.batchNormal1.bn2d.moving_variance, shape=(16,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      (relu1): PReLU<>\n",
      "      (down_conv_2): Conv3d<input_channels=16, output_channels=16, kernel_size=(3, 3, 3), stride=(1, 1, 1), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (relu2): PReLU<>\n",
      "      (residual): Conv3d<input_channels=1, output_channels=16, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal2): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=16, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=down1.down_conv.batchNormal2.bn2d.gamma, shape=(16,), dtype=Float32, requires_grad=True), beta=Parameter (name=down1.down_conv.batchNormal2.bn2d.beta, shape=(16,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=down1.down_conv.batchNormal2.bn2d.moving_mean, shape=(16,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=down1.down_conv.batchNormal2.bn2d.moving_variance, shape=(16,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      >\n",
      "    >\n",
      "  (down2): Down<\n",
      "    (down_conv): ResidualUnit<\n",
      "      (down_conv_1): Conv3d<input_channels=16, output_channels=32, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal1): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=down2.down_conv.batchNormal1.bn2d.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=down2.down_conv.batchNormal1.bn2d.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=down2.down_conv.batchNormal1.bn2d.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=down2.down_conv.batchNormal1.bn2d.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      (relu1): PReLU<>\n",
      "      (down_conv_2): Conv3d<input_channels=32, output_channels=32, kernel_size=(3, 3, 3), stride=(1, 1, 1), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (relu2): PReLU<>\n",
      "      (residual): Conv3d<input_channels=16, output_channels=32, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal2): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=down2.down_conv.batchNormal2.bn2d.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=down2.down_conv.batchNormal2.bn2d.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=down2.down_conv.batchNormal2.bn2d.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=down2.down_conv.batchNormal2.bn2d.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      >\n",
      "    >\n",
      "  (down3): Down<\n",
      "    (down_conv): ResidualUnit<\n",
      "      (down_conv_1): Conv3d<input_channels=32, output_channels=64, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal1): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=down3.down_conv.batchNormal1.bn2d.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=down3.down_conv.batchNormal1.bn2d.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=down3.down_conv.batchNormal1.bn2d.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=down3.down_conv.batchNormal1.bn2d.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      (relu1): PReLU<>\n",
      "      (down_conv_2): Conv3d<input_channels=64, output_channels=64, kernel_size=(3, 3, 3), stride=(1, 1, 1), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (relu2): PReLU<>\n",
      "      (residual): Conv3d<input_channels=32, output_channels=64, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal2): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=down3.down_conv.batchNormal2.bn2d.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=down3.down_conv.batchNormal2.bn2d.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=down3.down_conv.batchNormal2.bn2d.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=down3.down_conv.batchNormal2.bn2d.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      >\n",
      "    >\n",
      "  (down4): Down<\n",
      "    (down_conv): ResidualUnit<\n",
      "      (down_conv_1): Conv3d<input_channels=64, output_channels=128, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal1): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=down4.down_conv.batchNormal1.bn2d.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=down4.down_conv.batchNormal1.bn2d.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=down4.down_conv.batchNormal1.bn2d.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=down4.down_conv.batchNormal1.bn2d.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      (relu1): PReLU<>\n",
      "      (down_conv_2): Conv3d<input_channels=128, output_channels=128, kernel_size=(3, 3, 3), stride=(1, 1, 1), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (relu2): PReLU<>\n",
      "      (residual): Conv3d<input_channels=64, output_channels=128, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal2): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=down4.down_conv.batchNormal2.bn2d.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=down4.down_conv.batchNormal2.bn2d.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=down4.down_conv.batchNormal2.bn2d.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=down4.down_conv.batchNormal2.bn2d.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      >\n",
      "    >\n",
      "  (down5): Down<\n",
      "    (down_conv): ResidualUnit<\n",
      "      (down_conv_1): Conv3d<input_channels=128, output_channels=256, kernel_size=(3, 3, 3), stride=(1, 1, 1), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal1): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=down5.down_conv.batchNormal1.bn2d.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=down5.down_conv.batchNormal1.bn2d.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=down5.down_conv.batchNormal1.bn2d.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=down5.down_conv.batchNormal1.bn2d.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      (relu1): PReLU<>\n",
      "      (down_conv_2): Conv3d<input_channels=256, output_channels=256, kernel_size=(3, 3, 3), stride=(1, 1, 1), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (relu2): PReLU<>\n",
      "      (residual): Conv3d<input_channels=128, output_channels=256, kernel_size=(1, 1, 1), stride=(1, 1, 1), pad_mode=valid, padding=0, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal2): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=down5.down_conv.batchNormal2.bn2d.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=down5.down_conv.batchNormal2.bn2d.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=down5.down_conv.batchNormal2.bn2d.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=down5.down_conv.batchNormal2.bn2d.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      >\n",
      "    >\n",
      "  (up1): Up<\n",
      "    (conv3d_transpose): Conv3dTranspose<input_channels=384, output_channels=64, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros>\n",
      "    (conv): ResidualUnit<\n",
      "      (down_conv_1): Conv3d<input_channels=64, output_channels=64, kernel_size=(3, 3, 3), stride=(1, 1, 1), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal1): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=up1.conv.batchNormal1.bn2d.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=up1.conv.batchNormal1.bn2d.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=up1.conv.batchNormal1.bn2d.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=up1.conv.batchNormal1.bn2d.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      (relu1): PReLU<>\n",
      "      >\n",
      "    (batchNormal1): BatchNorm3d<\n",
      "      (bn2d): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=up1.batchNormal1.bn2d.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=up1.batchNormal1.bn2d.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=up1.batchNormal1.bn2d.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=up1.batchNormal1.bn2d.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
      "      >\n",
      "    (relu): PReLU<>\n",
      "    >\n",
      "  (up2): Up<\n",
      "    (conv3d_transpose): Conv3dTranspose<input_channels=128, output_channels=32, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros>\n",
      "    (conv): ResidualUnit<\n",
      "      (down_conv_1): Conv3d<input_channels=32, output_channels=32, kernel_size=(3, 3, 3), stride=(1, 1, 1), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal1): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=up2.conv.batchNormal1.bn2d.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=up2.conv.batchNormal1.bn2d.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=up2.conv.batchNormal1.bn2d.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=up2.conv.batchNormal1.bn2d.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      (relu1): PReLU<>\n",
      "      >\n",
      "    (batchNormal1): BatchNorm3d<\n",
      "      (bn2d): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=up2.batchNormal1.bn2d.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=up2.batchNormal1.bn2d.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=up2.batchNormal1.bn2d.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=up2.batchNormal1.bn2d.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
      "      >\n",
      "    (relu): PReLU<>\n",
      "    >\n",
      "  (up3): Up<\n",
      "    (conv3d_transpose): Conv3dTranspose<input_channels=64, output_channels=16, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros>\n",
      "    (conv): ResidualUnit<\n",
      "      (down_conv_1): Conv3d<input_channels=16, output_channels=16, kernel_size=(3, 3, 3), stride=(1, 1, 1), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      (batchNormal1): BatchNorm3d<\n",
      "        (bn2d): BatchNorm2d<num_features=16, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=up3.conv.batchNormal1.bn2d.gamma, shape=(16,), dtype=Float32, requires_grad=True), beta=Parameter (name=up3.conv.batchNormal1.bn2d.beta, shape=(16,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=up3.conv.batchNormal1.bn2d.moving_mean, shape=(16,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=up3.conv.batchNormal1.bn2d.moving_variance, shape=(16,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      (relu1): PReLU<>\n",
      "      >\n",
      "    (batchNormal1): BatchNorm3d<\n",
      "      (bn2d): BatchNorm2d<num_features=16, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=up3.batchNormal1.bn2d.gamma, shape=(16,), dtype=Float32, requires_grad=True), beta=Parameter (name=up3.batchNormal1.bn2d.beta, shape=(16,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=up3.batchNormal1.bn2d.moving_mean, shape=(16,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=up3.batchNormal1.bn2d.moving_variance, shape=(16,), dtype=Float32, requires_grad=False)>\n",
      "      >\n",
      "    (relu): PReLU<>\n",
      "    >\n",
      "  (up4): Up<\n",
      "    (conv3d_transpose): Conv3dTranspose<input_channels=32, output_channels=4, kernel_size=(3, 3, 3), stride=(2, 2, 2), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros>\n",
      "    (conv): ResidualUnit<\n",
      "      (down_conv_1): Conv3d<input_channels=4, output_channels=4, kernel_size=(3, 3, 3), stride=(1, 1, 1), pad_mode=pad, padding=1, dilation=(1, 1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCDHW>\n",
      "      >\n",
      "    (batchNormal1): BatchNorm3d<\n",
      "      (bn2d): BatchNorm2d<num_features=4, eps=1e-05, momentum=0.09999999999999998, gamma=Parameter (name=up4.batchNormal1.bn2d.gamma, shape=(4,), dtype=Float32, requires_grad=True), beta=Parameter (name=up4.batchNormal1.bn2d.beta, shape=(4,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=up4.batchNormal1.bn2d.moving_mean, shape=(4,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=up4.batchNormal1.bn2d.moving_variance, shape=(4,), dtype=Float32, requires_grad=False)>\n",
      "      >\n",
      "    (relu): PReLU<>\n",
      "    >\n",
      "  >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] KERNEL(10408,7f69f94a4080,python):2022-10-24-12:09:09.913.632 [mindspore/ccsrc/plugin/device/gpu/kernel/gpu_kernel_factory.cc:147] CheckSM] It is recommended to use devices with a computing capacity >= 7, but the current device's computing capacity is 6\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.ops import operations as P\n",
    "from src.unet3d_parts import Down, Up\n",
    "import numpy as np\n",
    "\n",
    "class UNet3d_(nn.Cell):\n",
    "    \"\"\"\n",
    "    UNet3d_ support fp32 and fp16(amp) training on GPU.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(UNet3d_, self).__init__()\n",
    "        self.n_channels = config.in_channels\n",
    "        self.n_classes = config.num_classes\n",
    "\n",
    "        # down\n",
    "        self.down1 = Down(in_channel=self.n_channels, out_channel=16, dtype=mstype.float32)\n",
    "        self.down2 = Down(in_channel=16, out_channel=32, dtype=mstype.float32)\n",
    "        self.down3 = Down(in_channel=32, out_channel=64, dtype=mstype.float32)\n",
    "        self.down4 = Down(in_channel=64, out_channel=128, dtype=mstype.float32)\n",
    "        self.down5 = Down(in_channel=128, out_channel=256, stride=1, kernel_size=(1, 1, 1), \\\n",
    "                          dtype=mstype.float32)\n",
    "        # up\n",
    "        self.up1 = Up(in_channel=256, down_in_channel=128, out_channel=64, \\\n",
    "                      dtype=mstype.float32)\n",
    "        self.up2 = Up(in_channel=64, down_in_channel=64, out_channel=32, \\\n",
    "                      dtype=mstype.float32)\n",
    "        self.up3 = Up(in_channel=32, down_in_channel=32, out_channel=16, \\\n",
    "                      dtype=mstype.float32)\n",
    "        self.up4 = Up(in_channel=16, down_in_channel=16, out_channel=self.n_classes, \\\n",
    "                      dtype=mstype.float32, is_output=True)\n",
    "\n",
    "    def construct(self, input_data):\n",
    "        x1 = self.down1(input_data)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        x5 = self.down5(x4)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        return x\n",
    "\n",
    "class UNet3d(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(UNet3d, self).__init__()\n",
    "        self.n_channels = config.in_channels\n",
    "        self.n_classes = config.num_classes\n",
    "\n",
    "        # down\n",
    "        self.transpose = P.Transpose()\n",
    "        self.down1 = Down(in_channel=self.n_channels, out_channel=16, dtype=mstype.float16).to_float(mstype.float16)\n",
    "        self.down2 = Down(in_channel=16, out_channel=32, dtype=mstype.float16).to_float(mstype.float16)\n",
    "        self.down3 = Down(in_channel=32, out_channel=64, dtype=mstype.float16).to_float(mstype.float16)\n",
    "        self.down4 = Down(in_channel=64, out_channel=128, dtype=mstype.float16).to_float(mstype.float16)\n",
    "        self.down5 = Down(in_channel=128, out_channel=256, stride=1, kernel_size=(1, 1, 1), \\\n",
    "                          dtype=mstype.float16).to_float(mstype.float16)\n",
    "        # up\n",
    "        self.up1 = Up(in_channel=256, down_in_channel=128, out_channel=64, \\\n",
    "                      dtype=mstype.float16).to_float(mstype.float16)\n",
    "        self.up2 = Up(in_channel=64, down_in_channel=64, out_channel=32, \\\n",
    "                      dtype=mstype.float16).to_float(mstype.float16)\n",
    "        self.up3 = Up(in_channel=32, down_in_channel=32, out_channel=16, \\\n",
    "                      dtype=mstype.float16).to_float(mstype.float16)\n",
    "        self.up4 = Up(in_channel=16, down_in_channel=16, out_channel=self.n_classes, \\\n",
    "                      dtype=mstype.float16, is_output=True).to_float(mstype.float16)\n",
    "\n",
    "        self.cast = P.Cast()\n",
    "\n",
    "    def construct(self, input_data):\n",
    "        input_data = self.cast(input_data, mstype.float16)\n",
    "        x1 = self.down1(input_data)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        x5 = self.down5(x4)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.cast(x, mstype.float32)\n",
    "        return x\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    x = ms.Tensor(np.zeros([1, 1, 224, 224, 96]), ms.float32)\n",
    "    model = UNet3d().set_train(True)\n",
    "    out = model(x)\n",
    "\n",
    "    # print(model)\n",
    "    print(\"UNet3D model input:\", x.shape)\n",
    "    print(\"UNet3D model output:\", out.shape)\n",
    "    print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "六、自定义metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from medpy.metric import binary\n",
    "\n",
    "class metrics:\n",
    "    def __init__(self, smooth=1e-5):\n",
    "        self.smooth=1e-5\n",
    "\n",
    "    def dice_metric(self, y_pred, y_label, empty_score=1.0):\n",
    "        \"\"\"Calculates the dice coefficient for the images\"\"\"\n",
    "        return binary.dc(y_pred, y_label)\n",
    "\n",
    "    def jc_metric(self, y_pred, y_label):\n",
    "        \"\"\"Jaccard coefficient\"\"\"\n",
    "        return binary.jc(y_pred, y_label)\n",
    "\n",
    "    def hd95_metric(self, y_pred, y_label):\n",
    "        \"\"\"Calculates the hausdorff distance for the images\"\"\"\n",
    "        return binary.hd95(y_pred, y_label, voxelspacing=1)\n",
    "\n",
    "    def asd_metric(self, y_pred, y_label):\n",
    "        \"\"\"Average surface distance metric.\"\"\"\n",
    "        return binary.asd(y_pred, y_label, voxelspacing=None)\n",
    "\n",
    "    def assd_metric(self, y_pred, y_label):\n",
    "        \"\"\"Average symmetric surface distance metric.\"\"\"\n",
    "        return binary.assd(y_pred, y_label, voxelspacing=None)\n",
    "\n",
    "    def precision_metric(self, y_pred, y_label):\n",
    "        \"\"\"precision metric.\"\"\"\n",
    "        return binary.precision(y_pred, y_label, voxelspacing=None)\n",
    "\n",
    "    def sensitivity_metric(self, y_pred, y_label, smooth = 1e-5):\n",
    "        \"\"\"recall(also sensitivity) metric.\"\"\"\n",
    "        return binary.recall(y_pred, y_label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "七、设置不同的学习率策略"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# dyanmic learning rate\n",
    "import math\n",
    "\n",
    "def linear_warmup_learning_rate(current_step, warmup_steps, base_lr, init_lr):\n",
    "    lr_inc = (float(base_lr) - float(init_lr)) / float(warmup_steps)\n",
    "    learning_rate = float(init_lr) + lr_inc * current_step\n",
    "    return learning_rate\n",
    "\n",
    "def a_cosine_learning_rate(current_step, base_lr, warmup_steps, decay_steps):\n",
    "    base = float(current_step - warmup_steps) / float(decay_steps)\n",
    "    learning_rate = (1 + math.cos(base * math.pi)) / 2 * base_lr\n",
    "    return learning_rate\n",
    "\n",
    "def dynamic_lr(config, base_step):\n",
    "    \"\"\"dynamic learning rate generator\"\"\"\n",
    "    base_lr = config.lr\n",
    "    total_steps = int(base_step * config.epoch_size)\n",
    "    warmup_steps = config.warmup_step\n",
    "    lr = []\n",
    "    for i in range(total_steps):\n",
    "        if i < warmup_steps:\n",
    "            lr.append(linear_warmup_learning_rate(i, warmup_steps, base_lr, base_lr * config.warmup_ratio))\n",
    "        else:\n",
    "            lr.append(a_cosine_learning_rate(i, base_lr, warmup_steps, total_steps))\n",
    "    return lr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Copyright 2021 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"Moxing adapter for ModelArts\"\"\"\n",
    "\n",
    "import os\n",
    "import functools\n",
    "from mindspore import context\n",
    "# from src.model_utils.config import config\n",
    "\n",
    "_global_sync_count = 0\n",
    "\n",
    "def get_device_id():\n",
    "    device_id = os.getenv('DEVICE_ID', '0')\n",
    "    return int(device_id)\n",
    "\n",
    "\n",
    "def get_device_num():\n",
    "    device_num = os.getenv('RANK_SIZE', '1')\n",
    "    return int(device_num)\n",
    "\n",
    "\n",
    "def get_rank_id():\n",
    "    global_rank_id = os.getenv('RANK_ID', '0')\n",
    "    return int(global_rank_id)\n",
    "\n",
    "\n",
    "def get_job_id():\n",
    "    job_id = os.getenv('JOB_ID')\n",
    "    job_id = job_id if job_id != \"\" else \"default\"\n",
    "    return job_id\n",
    "\n",
    "def sync_data(from_path, to_path):\n",
    "    \"\"\"\n",
    "    Download data from remote obs to local directory if the first url is remote url and the second one is local path\n",
    "    Upload data from local directory to remote obs in contrast.\n",
    "    \"\"\"\n",
    "    import moxing as mox\n",
    "    import time\n",
    "    global _global_sync_count\n",
    "    sync_lock = \"/tmp/copy_sync.lock\" + str(_global_sync_count)\n",
    "    _global_sync_count += 1\n",
    "\n",
    "    # Each server contains 8 devices as most.\n",
    "    if get_device_id() % min(get_device_num(), 8) == 0 and not os.path.exists(sync_lock):\n",
    "        print(\"from path: \", from_path)\n",
    "        print(\"to path: \", to_path)\n",
    "        mox.file.copy_parallel(from_path, to_path)\n",
    "        print(\"===finish data synchronization===\")\n",
    "        try:\n",
    "            os.mknod(sync_lock)\n",
    "        except IOError:\n",
    "            pass\n",
    "        print(\"===save flag===\")\n",
    "\n",
    "    while True:\n",
    "        if os.path.exists(sync_lock):\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(\"Finish sync data from {} to {}.\".format(from_path, to_path))\n",
    "\n",
    "\n",
    "def moxing_wrapper(pre_process=None, post_process=None):\n",
    "    \"\"\"\n",
    "    Moxing wrapper to download dataset and upload outputs.\n",
    "    \"\"\"\n",
    "    def wrapper(run_func):\n",
    "        @functools.wraps(run_func)\n",
    "        def wrapped_func(*args, **kwargs):\n",
    "            # Download data from data_url\n",
    "            if config.enable_modelarts:\n",
    "                if config.data_url:\n",
    "                    sync_data(config.data_url, config.data_path)\n",
    "                    print(\"Dataset downloaded: \", os.listdir(config.data_path))\n",
    "                if config.checkpoint_url:\n",
    "                    sync_data(config.checkpoint_url, config.load_path)\n",
    "                    print(\"Preload downloaded: \", os.listdir(config.load_path))\n",
    "                if config.train_url:\n",
    "                    sync_data(config.train_url, config.output_path)\n",
    "                    print(\"Workspace downloaded: \", os.listdir(config.output_path))\n",
    "\n",
    "                context.set_context(save_graphs_path=os.path.join(config.output_path, str(get_rank_id())))\n",
    "                config.device_num = get_device_num()\n",
    "                config.device_id = get_device_id()\n",
    "                if not os.path.exists(config.output_path):\n",
    "                    os.makedirs(config.output_path)\n",
    "\n",
    "                if pre_process:\n",
    "                    pre_process()\n",
    "\n",
    "            run_func(*args, **kwargs)\n",
    "\n",
    "            # Upload data to train_url\n",
    "            if config.enable_modelarts:\n",
    "                if post_process:\n",
    "                    post_process()\n",
    "\n",
    "                if config.train_url:\n",
    "                    print(\"Start to copy output directory\")\n",
    "                    sync_data(config.output_path, config.train_url)\n",
    "        return wrapped_func\n",
    "    return wrapper\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "八、主函数进行训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "from mindspore import ops\n",
    "from mindspore import SummaryRecord\n",
    "import mindspore.common.dtype as mstype\n",
    "from mindspore import Tensor, Model, context\n",
    "from mindspore.context import ParallelMode\n",
    "from mindspore.communication.management import init, get_rank, get_group_size\n",
    "from mindspore.train.loss_scale_manager import FixedLossScaleManager\n",
    "\n",
    "if config.device_target == 'Ascend':\n",
    "    device_id = int(os.getenv('DEVICE_ID'))\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=config.device_target, save_graphs=False, \\\n",
    "                        device_id=device_id)\n",
    "else:\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=config.device_target, save_graphs=False)\n",
    "\n",
    "mindspore.set_seed(1)\n",
    "\n",
    "@moxing_wrapper()\n",
    "def train_net(run_distribute=False):\n",
    "    if run_distribute:\n",
    "        init()\n",
    "        if config.device_target == 'Ascend':\n",
    "            rank_id = get_device_id()\n",
    "            rank_size = get_device_num()\n",
    "        else:\n",
    "            rank_id = get_rank()\n",
    "            rank_size = get_group_size()\n",
    "        parallel_mode = ParallelMode.DATA_PARALLEL\n",
    "        context.set_auto_parallel_context(parallel_mode=parallel_mode,\n",
    "                                          device_num=rank_size,\n",
    "                                          gradients_mean=True)\n",
    "    else:\n",
    "        rank_id = 0\n",
    "        rank_size = 1\n",
    "    # (1) create dataloader\n",
    "    train_dataset = create_dataset(data_path=config.data_path + \"/image/\",\n",
    "                                   seg_path=config.data_path + \"/seg/\",\n",
    "                                   rank_size=rank_size,\n",
    "                                   rank_id=rank_id, is_training=True)\n",
    "    train_data_size = train_dataset.get_dataset_size()\n",
    "    print(\"train dataset length is:\", train_data_size)\n",
    "    # (2) construct network\n",
    "    if config.device_target == 'Ascend':\n",
    "        network = UNet3d()\n",
    "    else:\n",
    "        network = UNet3d_()\n",
    "\n",
    "    # (3) define loss funtion\n",
    "    loss_ce_fn = nn.CrossEntropyLoss()\n",
    "    loss_dice_fn = nn.DiceLoss(smooth=1e-5)\n",
    "    # (4) lr shedule and optimizor\n",
    "    lr = Tensor(dynamic_lr(config, train_data_size), mstype.float32)\n",
    "    optimizer = nn.Adam(params=network.trainable_params(), learning_rate=lr)\n",
    "    # (5) set training mode\n",
    "    network.set_train()\n",
    "    # (6) Start training\n",
    "    print(\"============== Starting Training ==============\")\n",
    "    def forward_fn(data, label):\n",
    "        logits = network(data)\n",
    "        loss_ce = loss_ce_fn(logits, label)\n",
    "        loss_dice = loss_dice_fn(logits, label)\n",
    "        loss = loss_dice + loss_ce\n",
    "        return loss, loss_dice, loss_ce, logits\n",
    "    # Get gradient function\n",
    "    grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True)\n",
    "    # Define function of one-step training\n",
    "    def train_step(data, label):\n",
    "        (loss, loss_dice, loss_ce, _), grads = grad_fn(data, label)\n",
    "        loss = ops.depend(loss, optimizer(grads))\n",
    "        return loss, loss_dice, loss_ce\n",
    "\n",
    "    with SummaryRecord('./summary_dir/summary_01') as summary_record:\n",
    "        for epoch in range(config.max_epoch):\n",
    "            for step, (data, label) in enumerate(train_dataset.create_tuple_iterator()):\n",
    "                loss, loss_dice, loss_ce = train_step(data, label)\n",
    "\n",
    "                current_step = epoch * train_data_size + step\n",
    "                current_lr = optimizer.get_lr()\n",
    "                summary_record.record(current_step)\n",
    "                summary_record.add_value('scalar', 'lr', current_lr)\n",
    "                summary_record.add_value('scalar', 'loss_total', loss)\n",
    "                summary_record.add_value('scalar', 'loss_dice', loss_dice)\n",
    "                summary_record.add_value('scalar', 'loss_ce', loss_ce)\n",
    "\n",
    "                loss, loss_dice, loss_ce = loss.asnumpy(), loss_dice.asnumpy(), loss_ce.asnumpy()\n",
    "                print(\"Epoch: %d [%d/%d] [%d/%d] lr:%.7f Loss: %.4f Loss_dice: %.4f Loss_ce: %.4f\" %\n",
    "                      (epoch, step, train_data_size, current_step, train_data_size*config.max_epoch,\n",
    "                       current_lr, loss, loss_dice, loss_ce))\n",
    "            # Save checkpoint\n",
    "            ckpt_save_dir = os.path.join(config.output_path, config.checkpoint_path)\n",
    "            mindspore.save_checkpoint(network, os.path.join(ckpt_save_dir, \"Epoch_\"+str(epoch)+\"_model.ckpt\"))\n",
    "            print(\"Saved Model to {}/Epoch_{}_model.ckpt\".format(ckpt_save_dir, epoch))\n",
    "\n",
    "    print(\"============== End Training ==============\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_net()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "九、模型预测"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def first(iterable, default=None):\n",
    "    \"\"\"\n",
    "    Returns the first item in the given iterable or `default` if empty, meaningful mostly with 'for' expressions.\n",
    "    \"\"\"\n",
    "    for i in iterable:\n",
    "        return i\n",
    "    return default\n",
    "\n",
    "def _get_scan_interval(image_size, roi_size, num_image_dims, overlap):\n",
    "    \"\"\"\n",
    "    Compute scan interval according to the image size, roi size and overlap.\n",
    "    Scan interval will be `int((1 - overlap) * roi_size)`, if interval is 0,\n",
    "    use 1 instead to make sure sliding window works.\n",
    "    \"\"\"\n",
    "    if len(image_size) != num_image_dims:\n",
    "        raise ValueError(\"image different from spatial dims.\")\n",
    "    if len(roi_size) != num_image_dims:\n",
    "        raise ValueError(\"roi size different from spatial dims.\")\n",
    "\n",
    "    scan_interval = []\n",
    "    for i in range(num_image_dims):\n",
    "        if roi_size[i] == image_size[i]:\n",
    "            scan_interval.append(int(roi_size[i]))\n",
    "        else:\n",
    "            interval = int(roi_size[i] * (1 - overlap))\n",
    "            scan_interval.append(interval if interval > 0 else 1)\n",
    "    return tuple(scan_interval)\n",
    "\n",
    "def dense_patch_slices(image_size, patch_size, scan_interval):\n",
    "    \"\"\"\n",
    "    Enumerate all slices defining ND patches of size `patch_size` from an `image_size` input image.\n",
    "\n",
    "    Args:\n",
    "        image_size: dimensions of image to iterate over\n",
    "        patch_size: size of patches to generate slices\n",
    "        scan_interval: dense patch sampling interval\n",
    "\n",
    "    Returns:\n",
    "        a list of slice objects defining each patch\n",
    "    \"\"\"\n",
    "    num_spatial_dims = len(image_size)\n",
    "    patch_size = patch_size\n",
    "    scan_num = []\n",
    "    for i in range(num_spatial_dims):\n",
    "        if scan_interval[i] == 0:\n",
    "            scan_num.append(1)\n",
    "        else:\n",
    "            num = int(math.ceil(float(image_size[i]) / scan_interval[i]))\n",
    "            scan_dim = first(d for d in range(num) if d * scan_interval[i] + patch_size[i] >= image_size[i])\n",
    "            scan_num.append(scan_dim + 1 if scan_dim is not None else 1)\n",
    "    starts = []\n",
    "    for dim in range(num_spatial_dims):\n",
    "        dim_starts = []\n",
    "        for idx in range(scan_num[dim]):\n",
    "            start_idx = idx * scan_interval[dim]\n",
    "            start_idx -= max(start_idx + patch_size[dim] - image_size[dim], 0)\n",
    "            dim_starts.append(start_idx)\n",
    "        starts.append(dim_starts)\n",
    "    out = np.asarray([x.flatten() for x in np.meshgrid(*starts, indexing=\"ij\")]).T\n",
    "    return [(slice(None),)*2 + tuple(slice(s, s + patch_size[d]) for d, s in enumerate(x)) for x in out]\n",
    "\n",
    "def create_sliding_window(image, roi_size, overlap):\n",
    "    num_image_dims = len(image.shape) - 2\n",
    "    if overlap < 0 or overlap >= 1:\n",
    "        raise AssertionError(\"overlap must be >= 0 and < 1.\")\n",
    "    image_size_temp = list(image.shape[2:])\n",
    "    image_size = tuple(max(image_size_temp[i], roi_size[i]) for i in range(num_image_dims))\n",
    "\n",
    "    scan_interval = _get_scan_interval(image_size, roi_size, num_image_dims, overlap)\n",
    "    slices = dense_patch_slices(image_size, roi_size, scan_interval)\n",
    "    windows_sliding = [image[slice] for slice in slices]\n",
    "    return windows_sliding, slices\n",
    "\n",
    "def CalculateDice(y_pred, label):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y_pred: predictions. As for classification tasks,\n",
    "            `y_pred` should has the shape [BN] where N is larger than 1. As for segmentation tasks,\n",
    "            the shape should be [BNHW] or [BNHWD].\n",
    "        label: ground truth, the first dim is batch.\n",
    "    \"\"\"\n",
    "    metric = metrics()\n",
    "    y_pred_output = np.expand_dims(np.argmax(y_pred, axis=1), axis=1)\n",
    "    y_pred = one_hot(y_pred_output)\n",
    "    y = one_hot(label)\n",
    "    y_pred, y = ignore_background(y_pred, y)\n",
    "\n",
    "    dice = metric.dice_metric(y_pred, y)\n",
    "    hd95 = metric.hd95_metric(y_pred, y)\n",
    "    jc = metric.jc_metric(y_pred, y)\n",
    "    asd = metric.asd_metric(y_pred, y)\n",
    "    sens = metric.sensitivity_metric(y_pred, y)\n",
    "    return dice, hd95, jc, asd, sens\n",
    "\n",
    "def ignore_background(y_pred, label):\n",
    "    \"\"\"\n",
    "    This function is used to remove background (the first channel) for `y_pred` and `y`.\n",
    "    Args:\n",
    "        y_pred: predictions. As for classification tasks,\n",
    "            `y_pred` should has the shape [BN] where N is larger than 1. As for segmentation tasks,\n",
    "            the shape should be [BNHW] or [BNHWD].\n",
    "        label: ground truth, the first dim is batch.\n",
    "    \"\"\"\n",
    "    label = label[:, 1:] if label.shape[1] > 1 else label\n",
    "    y_pred = y_pred[:, 1:] if y_pred.shape[1] > 1 else y_pred\n",
    "    return y_pred, label\n",
    "\n",
    "def one_hot(labels):\n",
    "    N, _, D, H, W = labels.shape\n",
    "    labels = np.reshape(labels, (N, -1))\n",
    "    labels = labels.astype(np.int32)\n",
    "    N, K = labels.shape\n",
    "    one_hot_encoding = np.zeros((N, config.num_classes, K), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        for j in range(K):\n",
    "            one_hot_encoding[i, labels[i][j], j] = 1\n",
    "    labels = np.reshape(one_hot_encoding, (N, config.num_classes, D, H, W))\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset length is: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(12961:140093130686592,_MPWorker-22):2022-10-24-12:09:42.356.231 [mindspore/dataset/engine/queue.py:120] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 119537664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current image shape is (1, 1, 512, 512, 140)\n",
      "The 0 batch Dice: 0.9806, HD95:0.0000, JC: 0.9620, ASD: 0.0592, Sens: 0.9808\n",
      "current image shape is (1, 1, 512, 512, 158)\n",
      "The 1 batch Dice: 0.9847, HD95:0.0000, JC: 0.9698, ASD: 0.1013, Sens: 0.9817\n",
      "current image shape is (1, 1, 512, 512, 133)\n",
      "The 2 batch Dice: 0.9771, HD95:0.0000, JC: 0.9552, ASD: 0.5383, Sens: 0.9791\n",
      "current image shape is (1, 1, 512, 512, 114)\n",
      "The 3 batch Dice: 0.9581, HD95:0.0000, JC: 0.9196, ASD: 2.2986, Sens: 0.9883\n",
      "current image shape is (1, 1, 512, 512, 350)\n",
      "The 4 batch Dice: 0.9821, HD95:0.0000, JC: 0.9649, ASD: 0.0508, Sens: 0.9826\n",
      "current image shape is (1, 1, 512, 512, 290)\n",
      "The 5 batch Dice: 0.9753, HD95:0.0000, JC: 0.9517, ASD: 0.6219, Sens: 0.9759\n",
      "current image shape is (1, 1, 512, 512, 172)\n",
      "The 6 batch Dice: 0.9894, HD95:0.0000, JC: 0.9789, ASD: 0.0175, Sens: 0.9922\n",
      "current image shape is (1, 1, 512, 512, 125)\n",
      "The 7 batch Dice: 0.9585, HD95:0.0000, JC: 0.9203, ASD: 0.0504, Sens: 0.9576\n",
      "current image shape is (1, 1, 512, 512, 248)\n",
      "The 8 batch Dice: 0.9719, HD95:0.0000, JC: 0.9453, ASD: 1.3359, Sens: 0.9803\n",
      "current image shape is (1, 1, 512, 512, 481)\n",
      "The 9 batch Dice: 0.9688, HD95:0.0000, JC: 0.9394, ASD: 0.7419, Sens: 0.9608\n",
      "**********************End Eval***************************************\n",
      "The average Dice: 0.9746, HD95:0.0000, JC: 0.9507, ASD: 0.5816, Sens: 0.9779\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore import Model, context, Tensor\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "\n",
    "config.device_target = \"GPU\"\n",
    "if config.device_target == 'Ascend':\n",
    "    device_id = int(os.getenv('DEVICE_ID'))\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=config.device_target, save_graphs=False, \\\n",
    "                        device_id=device_id)\n",
    "else:\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=config.device_target, save_graphs=False)\n",
    "\n",
    "# @moxing_wrapper()\n",
    "def test_net(data_path, ckpt_path):\n",
    "    data_dir = data_path + \"/image/\"\n",
    "    seg_dir = data_path + \"/seg/\"\n",
    "    eval_dataset = create_dataset(data_path=data_dir, seg_path=seg_dir, is_training=False)\n",
    "    eval_data_size = eval_dataset.get_dataset_size()\n",
    "    print(\"test dataset length is:\", eval_data_size)\n",
    "\n",
    "    metrics_score = {}\n",
    "    metrics_score[\"dice\"] = 0\n",
    "    metrics_score[\"hd95\"] = 0\n",
    "    metrics_score[\"jc\"] = 0\n",
    "\n",
    "    if config.device_target == 'Ascend':\n",
    "        network = UNet3d()\n",
    "    else:\n",
    "        network = UNet3d_()\n",
    "    network.set_train(False)\n",
    "    param_dict = load_checkpoint(ckpt_path)\n",
    "    load_param_into_net(network, param_dict)\n",
    "    # metrics\n",
    "    results = {}\n",
    "    results[\"dice\"] = 0\n",
    "    results[\"hd95\"] = 0\n",
    "    results[\"jc\"] = 0\n",
    "    results[\"asd\"] = 0\n",
    "    results[\"sens\"] = 0\n",
    "    model = Model(network)\n",
    "    index = 0\n",
    "    total_dice = 0\n",
    "    config.batch_size=1\n",
    "    for batch in eval_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):\n",
    "        image = batch[\"image\"]\n",
    "        seg = batch[\"seg\"]\n",
    "        print(\"current image shape is {}\".format(image.shape), flush=True)\n",
    "        sliding_window_list, slice_list = create_sliding_window(image, config.roi_size, config.overlap)\n",
    "        image_size = (config.batch_size, config.num_classes) + image.shape[2:]\n",
    "        output_image = np.zeros(image_size, np.float32)\n",
    "        count_map = np.zeros(image_size, np.float32)\n",
    "        importance_map = np.ones(config.roi_size, np.float32)\n",
    "        for window, slice_ in zip(sliding_window_list, slice_list):\n",
    "            window_image = Tensor(window, mstype.float32)\n",
    "            pred_probs = model.predict(window_image)\n",
    "            output_image[slice_] += pred_probs.asnumpy()\n",
    "            count_map[slice_] += importance_map\n",
    "        output_image = output_image / count_map\n",
    "        dice, hd95, jc, asd, sens = CalculateDice(output_image, seg)\n",
    "\n",
    "        print(\"The %d batch Dice: %.4f, HD95:%.4f, JC: %.4f, ASD: %.4f, Sens: %.4f\"%(index, dice, hd95, jc, asd, sens))\n",
    "        total_dice += dice\n",
    "        results[\"dice\"] += dice\n",
    "        results[\"hd95\"] += hd95\n",
    "        results[\"jc\"] += jc\n",
    "        results[\"asd\"] += asd\n",
    "        results[\"sens\"] += sens\n",
    "        index = index + 1\n",
    "    avg_dice = results[\"dice\"] / eval_data_size\n",
    "    avg_hd95 = results[\"hd95\"] / eval_data_size\n",
    "    avg_jc = results[\"jc\"] / eval_data_size\n",
    "    avg_asd = results[\"asd\"] / eval_data_size\n",
    "    avg_sens = results[\"sens\"] / eval_data_size\n",
    "    print(\"**********************End Eval***************************************\")\n",
    "    print(\"The average Dice: %.4f, HD95:%.4f, JC: %.4f, ASD: %.4f, Sens: %.4f\" %\n",
    "          (avg_dice, avg_hd95, avg_jc, avg_asd, avg_sens))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_net(data_path=\"data/LUNA16/val/\",\n",
    "             ckpt_path=\"./output/checkpoint/Epoch_9_model.ckpt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
